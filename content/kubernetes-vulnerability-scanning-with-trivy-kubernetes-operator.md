---
title: Making use of Trivy for container vulnerability scanning of Kubernetes workloads
description: Using the Trivy Kubernetes operator to continuously scan running workloads for vulnerabilities.
tags: Security, Kubernetes, Trivy, Containers
breadcrumbs: false
---

## Preamble

Scanning software for vulnerabilities is a crucial part of the software development process. Ideally we would detect vulnerabilities in software before its deployed, but new risks are discovered all the time so we need complete and continuous coverage. Discovering the exact set of images in use is a challenge, especially with Kubernetes workloads managed by operators. With so many useful additions to Kubernetes clusters there can be literally hundreds of different container images in use. 

A rudimentary approach I've taken in the past is to parse the all the manifests that get applied to the cluster as part of a CI validation step. This gets you most of the way and is improved by using the [rendered manifests pattern](https://akuity.io/blog/the-rendered-manifests-pattern), because any templating has been rendered out. But this is not sufficient because it's hard to detect which container images are going to be used by an operator acting upon custom resources; a custom resource may or may not require an image declaration and it might only be a partial of that image reference, e.g. just the version or reposotory name. Additionally there may be containers used as part of jobs created by an operator that won't always be running. This leaves a gap in the coverage of the scanning process, which needs addressing.

The best way to discover the full set of images in use is to continuously scan the running workloads. The approach I will be taking is to use the trivy kubernetes operator to scan workloads as they are admitted to the cluster.

## About trivy

Trivy is a versatile open-source tool for finding vulnerabilities and misconfigurations in software. It can be used standalone, in your IDE, in CI/CD pipelines, or as a Kubernetes operator which makes it a great solution for consistent integration thoughout the software development lifecycle.

It's important to understand where the feature set of the OSS version of trivy sits withing the broader security landscape, so that you know what you're getting and what's missing. The [trivy feature comparison](https://trivy.dev/latest/commercial/compare/) is a good place to start.

When run as an operator trivy watches for workload creation and triggers a scan of the workload's container images. The results are stored as a Kubernetes custom resource in the namespace of the workload. By default, scan results have a TTL of 24 hours, meaning the workload will be re-scanned every day to cover any new vulnerabilities that have been discovered.

## Running trivy locally

Trivy can be installed from most package managers or you can download the binary directly. Once you have it installed, you can start scanning quite easily:

```shell
trivy image busybox
```
```
alpine (alpine 3.21.2)

Total: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

┌────────────┬────────────────┬──────────┬────────┬───────────────────┬───────────────┬─────────────────────────────────────────────────────────────┐
│  Library   │ Vulnerability  │ Severity │ Status │ Installed Version │ Fixed Version │                            Title                            │
├────────────┼────────────────┼──────────┼────────┼───────────────────┼───────────────┼─────────────────────────────────────────────────────────────┤
│ libcrypto3 │ CVE-2024-13176 │ MEDIUM   │ fixed  │ 3.3.2-r4          │ 3.3.2-r5      │ openssl: Timing side-channel in ECDSA signature computation │
│            │                │          │        │                   │               │ https://avd.aquasec.com/nvd/cve-2024-13176                  │
├────────────┤                │          │        │                   │               │                                                             │
│ libssl3    │                │          │        │                   │               │                                                             │
│            │                │          │        │                   │               │                                                             │
└────────────┴────────────────┴──────────┴────────┴───────────────────┴───────────────┴─────────────────────────────────────────────────────────────┘
```

Cool, piece of cake! How about a cluster now?:

```shell
kind create cluster
trivy k8s --report summary --quiet
```


```
Summary Report for kind-kind


Workload Assessment
┌────────────────────┬───────────────────────────────────┬─────────────────────┬───────────────────┬───────────────────┐
│     Namespace      │             Resource              │   Vulnerabilities   │ Misconfigurations │      Secrets      │
│                    │                                   ├───┬───┬────┬────┬───┼───┬───┬───┬───┬───┼───┬───┬───┬───┬───┤
│                    │                                   │ C │ H │ M  │ L  │ U │ C │ H │ M │ L │ U │ C │ H │ M │ L │ U │
├────────────────────┼───────────────────────────────────┼───┼───┼────┼────┼───┼───┼───┼───┼───┼───┼───┼───┼───┼───┼───┤
│ local-path-storage │ ConfigMap/local-path-config       │   │   │    │    │   │   │   │ 1 │   │   │   │   │   │   │   │
│ local-path-storage │ Deployment/local-path-provisioner │ 1 │ 1 │ 16 │ 11 │ 1 │   │ 2 │ 3 │ 9 │   │   │   │   │   │   │
└────────────────────┴───────────────────────────────────┴───┴───┴────┴────┴───┴───┴───┴───┴───┴───┴───┴───┴───┴───┴───┘
Severities: C=CRITICAL H=HIGH M=MEDIUM L=LOW U=UNKNOWN


Infra Assessment
┌─────────────┬────────────────────────────────────────────────┬─────────────────────┬────────────────────┬───────────────────┐
│  Namespace  │                    Resource                    │   Vulnerabilities   │ Misconfigurations  │      Secrets      │
│             │                                                ├───┬───┬────┬────┬───┼───┬───┬───┬────┬───┼───┬───┬───┬───┬───┤
│             │                                                │ C │ H │ M  │ L  │ U │ C │ H │ M │ L  │ U │ C │ H │ M │ L │ U │
├─────────────┼────────────────────────────────────────────────┼───┼───┼────┼────┼───┼───┼───┼───┼────┼───┼───┼───┼───┼───┼───┤
│ kube-system │ DaemonSet/kube-proxy                           │ 1 │ 1 │ 8  │ 14 │   │   │ 3 │ 5 │ 9  │   │   │   │   │   │   │
│ kube-system │ Service/kube-dns                               │   │   │    │    │   │   │   │ 1 │    │   │   │   │   │   │   │
│ kube-system │ ConfigMap/extension-apiserver-authentication   │   │   │    │    │   │   │   │ 1 │    │   │   │   │   │   │   │
│ kube-system │ DaemonSet/kindnet                              │   │ 2 │ 19 │ 16 │   │   │ 3 │ 6 │ 5  │   │   │   │   │   │   │
│ kube-system │ Pod/kube-controller-manager-kind-control-plane │ 1 │ 1 │ 7  │    │   │   │ 2 │ 3 │ 10 │   │   │   │   │   │   │
│ kube-system │ Pod/kube-scheduler-kind-control-plane          │ 1 │ 1 │ 6  │    │   │   │ 2 │ 3 │ 8  │   │   │   │   │   │   │
│ kube-system │ Deployment/coredns                             │ 1 │ 2 │ 7  │ 1  │ 1 │   │   │ 5 │ 4  │   │   │   │   │   │   │
│ kube-system │ Pod/etcd-kind-control-plane                    │ 4 │ 4 │ 15 │ 4  │   │   │ 2 │ 3 │ 6  │   │   │   │   │   │   │
│ kube-system │ Pod/kube-apiserver-kind-control-plane          │ 1 │ 1 │ 7  │    │   │   │ 2 │ 4 │ 16 │   │   │   │   │   │   │
│             │ Node/kind-control-plane                        │   │   │    │    │   │ 1 │ 3 │   │ 1  │   │   │   │   │   │   │
└─────────────┴────────────────────────────────────────────────┴───┴───┴────┴────┴───┴───┴───┴───┴────┴───┴───┴───┴───┴───┴───┘
Severities: C=CRITICAL H=HIGH M=MEDIUM L=LOW U=UNKNOWN


RBAC Assessment
┌────────────────────┬────────────────────────────────────────────────────────────────────┬───────────────────┐
│     Namespace      │                              Resource                              │  RBAC Assessment  │
│                    │                                                                    ├───┬───┬───┬───┬───┤
│                    │                                                                    │ C │ H │ M │ L │ U │
├────────────────────┼────────────────────────────────────────────────────────────────────┼───┼───┼───┼───┼───┤
│ local-path-storage │ Role/local-path-provisioner-role                                   │   │   │ 1 │   │   │
│ kube-system        │ Role/system:controller:bootstrap-signer                            │   │   │ 1 │   │   │
│ kube-system        │ Role/system:controller:cloud-provider                              │   │   │ 1 │   │   │
│ kube-system        │ Role/system::leader-locking-kube-scheduler                         │   │   │ 1 │   │   │
│ kube-system        │ Role/system:controller:token-cleaner                               │   │   │ 1 │   │   │
│ kube-system        │ Role/system::leader-locking-kube-controller-manager                │   │   │ 1 │   │   │
│ kube-public        │ Role/system:controller:bootstrap-signer                            │   │   │ 1 │   │   │
│ kube-public        │ RoleBinding/kubeadm:bootstrap-signer-clusterinfo                   │ 1 │   │   │   │   │
│                    │ ClusterRole/admin                                                  │ 3 │ 4 │ 6 │   │   │
│                    │ ClusterRole/system:controller:node-controller                      │   │   │ 1 │   │   │
│                    │ ClusterRole/system:controller:endpointslice-controller             │   │ 1 │   │   │   │
│                    │ ClusterRole/system:controller:daemon-set-controller                │   │   │ 1 │   │   │
│                    │ ClusterRole/edit                                                   │ 2 │ 4 │ 6 │   │   │
│                    │ ClusterRole/system:aggregate-to-edit                               │ 2 │ 4 │ 6 │   │   │
│                    │ ClusterRole/system:controller:cronjob-controller                   │   │   │ 3 │   │   │
│                    │ ClusterRole/system:controller:endpoint-controller                  │   │ 1 │   │   │   │
│                    │ ClusterRole/system:controller:resourcequota-controller             │ 1 │   │   │   │   │
│                    │ ClusterRole/system:kube-controller-manager                         │ 5 │   │   │   │   │
│                    │ ClusterRole/system:aggregate-to-admin                              │ 1 │   │   │   │   │
│                    │ ClusterRole/system:controller:deployment-controller                │   │   │ 3 │   │   │
│                    │ ClusterRole/system:kube-scheduler                                  │   │   │ 1 │   │   │
│                    │ ClusterRoleBinding/cluster-admin                                   │   │   │ 1 │   │   │
│                    │ ClusterRole/system:controller:namespace-controller                 │ 1 │   │   │   │   │
│                    │ ClusterRole/system:controller:legacy-service-account-token-cleaner │ 1 │   │   │   │   │
│                    │ ClusterRole/system:controller:persistent-volume-binder             │   │   │ 1 │   │   │
│                    │ ClusterRole/system:controller:pod-garbage-collector                │   │   │ 1 │   │   │
│                    │ ClusterRole/system:controller:statefulset-controller               │   │   │ 1 │   │   │
│                    │ ClusterRole/system:controller:endpointslicemirroring-controller    │   │ 1 │   │   │   │
│                    │ ClusterRole/system:controller:job-controller                       │   │   │ 2 │   │   │
│                    │ ClusterRole/system:node                                            │ 1 │   │ 1 │   │   │
│                    │ ClusterRoleBinding/kubeadm:cluster-admins                          │   │   │ 1 │   │   │
│                    │ ClusterRole/system:controller:root-ca-cert-publisher               │   │   │ 1 │   │   │
│                    │ ClusterRole/system:controller:replicaset-controller                │   │   │ 2 │   │   │
│                    │ ClusterRole/cluster-admin                                          │ 2 │   │   │   │   │
│                    │ ClusterRole/system:controller:horizontal-pod-autoscaler            │ 2 │   │   │   │   │
│                    │ ClusterRole/system:controller:replication-controller               │   │   │ 2 │   │   │
│                    │ ClusterRole/system:controller:ttl-after-finished-controller        │   │   │ 1 │   │   │
│                    │ ClusterRole/system:controller:generic-garbage-collector            │ 1 │   │   │   │   │
└────────────────────┴────────────────────────────────────────────────────────────────────┴───┴───┴───┴───┴───┘
Severities: C=CRITICAL H=HIGH M=MEDIUM L=LOW U=UNKNOWN
```

Nice. It scanned everything and found a bunch of stuff we would probably want to address if we were running this in production. These commands will be useful when scripting a CI pipeline. For example you might prevent a deployment if the scan finds vulnerabilities with a higher severity than is accepable:

```shell
if trivy image alpine --quiet --severity MEDIUM,HIGH,CRITICAL --exit-code 1 --output /dev/null; then
  echo "No vulnerabilities :)"
else
  echo "Unacceptable vulnerabilities found :("
fi
```
```
Unacceptable vulnerabilities found :(
```

## Installing the trivy kubernetes operator

The easiest way to get the trivy kubernetes operator up and running is to use the Helm chart.

```shell
helm install trivy-operator oci://ghcr.io/aquasecurity/helm-charts/trivy-operator \
     --namespace trivy-system \
     --create-namespace
```
This installs the operator in its own namespace with defaults that are fine for exploration. You can review the chart's values documentation for customising the installation, such as setting the severity threshold for vulnerabilities to report on, or the scan interval.

Once installed it quickly gets to work scanning the workloads in the cluster. You can see the results by running:

```shell
kubectl get vuln --all-namespaces -o wide
```

```
NAMESPACE            NAME                                                             REPOSITORY                                       TAG                  SCANNER   AGE   CRITICAL   HIGH   MEDIUM   LOW   UNKNOWN
kube-system          daemonset-kindnet-kindnet-cni                                    kindest/kindnetd                                 v20241212-9f82dd49   Trivy     4m   0          2      19       16    0
kube-system          daemonset-kube-proxy-kube-proxy                                  kube-proxy                                       v1.32.0              Trivy     4m   1          1      8        14    0
kube-system          pod-8b4f55974                                                    kube-controller-manager                          v1.32.0              Trivy     4m   1          1      7        0     0
kube-system          pod-etcd-kind-control-plane-etcd                                 etcd                                             3.5.16-0             Trivy     4m   4          4      15       4     0
kube-system          pod-kube-apiserver-kind-control-plane-kube-apiserver             kube-apiserver                                   v1.32.0              Trivy     4m   1          1      7        0     0
kube-system          pod-kube-scheduler-kind-control-plane-kube-scheduler             kube-scheduler                                   v1.32.0              Trivy     4m   1          1      6        0     0
kube-system          replicaset-coredns-668d6bf9bc-coredns                            coredns/coredns                                  v1.11.3              Trivy     4m   1          2      7        1     1
local-path-storage   replicaset-7dfc7cc874                                            kindest/local-path-provisioner                   v20241212-8ac705d0   Trivy     4m   1          1      16       11    1
trivy-system         replicaset-trivy-operator-9d6f58f77-trivy-operator               aquasec/trivy-operator                           0.24.0               Trivy     4m   0          0      3        2     0
```

## Enable monitoring for the trivy operator

A production grade cluster will already have monitoring in place and there are many ways to do that. But for the purposes of this blog post I will use a quick and dirty installation of [kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack).

```shell
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm install kp prometheus-community/kube-prometheus-stack \
     --namespace monitoring \
     --create-namespace
```

Trivy comes with support for scraping metrics in prometheus format. To enable this you can set the `serviceMonitor.enabled` value to `true` when installing the operator. The version of the prometheus operator we installed looks for serviceMonitor resources with the label `release=<release_name>` so we need to set that too. Since I installed the moniteoting stack with the release name `kp` I will set the label to that value:

```shell
helm upgrade trivy-operator oci://ghcr.io/aquasecurity/helm-charts/trivy-operator \
     --namespace trivy-system --reuse-values --set serviceMonitor.enabled=true \
     --set serviceMonitor.labels.release=kp
```

Looking at the secret for the Grafana instance, the username defaults to `admin` and the password defaults to `prom-operator` You can get the password by running:

```shell
kubectl get secret kp-grafana -n monitoring -o jsonpath="{.data.admin-password}" | base64 -d
```

Port forward the Grafana service to your local machine and browse to [http://localhost:8080](http://localhost:8080):

```shell
kubectl port-forward service/kp-grafana -n monitoring 8080:80
```

Now look for the `+` on the top right of the screen to add a dashboard and click "import dashboard". The trivy operator dashboard ID is `17813` so enter that and click load. Select the prometheus data source and click import. You should now see the trivy operator dashboard. 

Expand the panels to see all the fun colours and how much work you now have on your hands 🎉

Next steps would be to add alerts for new vulnerabilities according to your organisation's policy. You might also consider automatically raising tickets.
